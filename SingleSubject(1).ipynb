{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309af0d2-61fc-46d4-8fea-fa5f971b44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nilearn.plotting as niplot\n",
    "import ipywidgets as widgets\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import IntSlider, VBox, HBox, Output\n",
    "from IPython.display import display\n",
    "from nilearn.image import resample_to_img\n",
    "from nilearn.image import smooth_img\n",
    "from nilearn.masking import apply_mask, unmask\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.gridspec as gridspec\n",
    "from nilearn.interfaces.fmriprep import load_confounds\n",
    "from nilearn.signal import clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba183aaf-9d9d-4c94-ab6d-717b5d8d7b85",
   "metadata": {},
   "source": [
    "Reference article for imaging protocol and experimen design: 10.1093/cercor/bhz157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f02036-8e1f-4946-b9a3-ca50063ccf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def interactive_fmri_viewer(img, mask=None):\n",
    "    \"\"\"\n",
    "    Interactive viewer for 4D fMRI data (axial slices over time), with optional mask overlay.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    img : nibabel.Nifti1Image\n",
    "        Loaded 4D fMRI image.\n",
    "\n",
    "    mask : nibabel.Nifti1Image or None\n",
    "        Optional 3D or 4D binary mask image to overlay. Must be in same space as img.\n",
    "\n",
    "    Usage:\n",
    "    ------\n",
    "    >>> import nibabel as nib\n",
    "    >>> img = nib.load(\"peer_run1.nii.gz\")\n",
    "    >>> mask = nib.load(\"eye_mask_right_resampled.nii.gz\")  # 3D or 4D mask\n",
    "    >>> interactive_fmri_viewer(img, mask)\n",
    "    \"\"\"\n",
    "    data = img.get_fdata()\n",
    "    x, y, z, t = data.shape\n",
    "\n",
    "    mask_data = None\n",
    "    if mask is not None:\n",
    "        mask_data = mask.get_fdata().astype(bool)\n",
    "        # Check mask dimension\n",
    "        if mask_data.ndim == 3:\n",
    "            is_4d_mask = False\n",
    "        elif mask_data.ndim == 4:\n",
    "            if mask_data.shape[3] != t:\n",
    "                raise ValueError(f\"Mask time dimension ({mask_data.shape[3]}) does not match image ({t})\")\n",
    "            is_4d_mask = True\n",
    "        else:\n",
    "            raise ValueError(\"Mask must be either 3D or 4D\")\n",
    "\n",
    "    @widgets.interact(\n",
    "        z=widgets.IntSlider(min=0, max=z - 1, step=1, value=z // 2, description=\"Axial Slice\"),\n",
    "        t=widgets.IntSlider(min=0, max=t - 1, step=1, value=0, description=\"Time Point\")\n",
    "    )\n",
    "    def show_fmri_slice(z=0, t=0):\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(data[:, :, z, t].T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "        if mask_data is not None:\n",
    "            if is_4d_mask:\n",
    "                mask_slice = mask_data[:, :, z, t]\n",
    "            else:\n",
    "                mask_slice = mask_data[:, :, z]\n",
    "            # Overlay the mask in red with alpha blending\n",
    "            masked_slice = np.ma.masked_where(~mask_slice, mask_slice)\n",
    "            plt.imshow(masked_slice.T, cmap='Reds', alpha=0.4, origin=\"lower\")\n",
    "\n",
    "        plt.title(f\"Time: {t}, Slice: {z}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def correlation_with_gaze_task(func_img, mask=None, axis=None):\n",
    "   \n",
    "    # Apply mask\n",
    "    masked_data = apply_mask(func_img, mask)  # shape (timepoints, voxels)\n",
    "\n",
    "    # Get regressor\n",
    "    regressor = stimuli_repeated[axis].values  # shape (timepoints,)\n",
    "\n",
    "    # Compute voxelwise correlations\n",
    "    correlations = np.array([\n",
    "        pearsonr(masked_data[:, v], regressor)[0]\n",
    "        for v in range(masked_data.shape[1])\n",
    "    ])\n",
    "\n",
    "    # Reconstruct 3D correlation map\n",
    "    correlation_img = unmask(correlations, mask)\n",
    "\n",
    "    return correlation_img\n",
    "\n",
    "from scipy.ndimage import center_of_mass\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "def compute_weighted_centers(img_4d, top10_mask_4d):\n",
    "    \"\"\"\n",
    "    Computes weighted center of mass for each time point using top 10% voxel mask.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    img_4d : nibabel.Nifti1Image\n",
    "        4D fMRI image.\n",
    "\n",
    "    top10_mask_4d : nibabel.Nifti1Image\n",
    "        4D binary mask image indicating top 10% voxels for each time point.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    centers : np.ndarray of shape (T, 3)\n",
    "        Weighted center of mass (x, y, z) at each time point.\n",
    "    \"\"\"\n",
    "    data = img_4d.get_fdata()\n",
    "    mask = top10_mask_4d.get_fdata().astype(bool)\n",
    "    T = data.shape[3]\n",
    "\n",
    "    centers = []\n",
    "    for t in tqdm(range(T), desc=\"Computing weighted centers\"):\n",
    "        vol = data[..., t]\n",
    "        mask_t = mask[..., t]\n",
    "\n",
    "        if np.sum(mask_t) == 0:\n",
    "            centers.append((np.nan, np.nan, np.nan))\n",
    "            continue\n",
    "\n",
    "        # Use voxel intensities within the mask as weights\n",
    "        weights = vol * mask_t\n",
    "        com = center_of_mass(weights)\n",
    "        centers.append(com)\n",
    "\n",
    "    return np.array(centers)\n",
    "\n",
    "\n",
    "def compute_unweighted_centers(img_4d, top10_mask_4d):\n",
    "    \"\"\"\n",
    "    Computes unweighted (geometric) center of mass for each time point using top 10% voxel mask.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    img_4d : nibabel.Nifti1Image\n",
    "        4D fMRI image (only used to get time dimension shape).\n",
    "\n",
    "    top10_mask_4d : nibabel.Nifti1Image\n",
    "        4D binary mask image indicating top 10% voxels for each time point.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    centers : np.ndarray of shape (T, 3)\n",
    "        Geometric center of mass (x, y, z) at each time point.\n",
    "    \"\"\"\n",
    "    mask = top10_mask_4d.get_fdata().astype(bool)\n",
    "    T = mask.shape[3]\n",
    "\n",
    "    centers = []\n",
    "    for t in tqdm(range(T), desc=\"Computing unweighted centers\"):\n",
    "        mask_t = mask[..., t]\n",
    "\n",
    "        if np.sum(mask_t) == 0:\n",
    "            centers.append((np.nan, np.nan, np.nan))\n",
    "            continue\n",
    "\n",
    "        # Unweighted center of mass: center_of_mass of a binary mask\n",
    "        com = center_of_mass(mask_t)\n",
    "        centers.append(com)\n",
    "\n",
    "    return np.array(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96898685-1e41-4b91-a134-22a0b34504ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_dir=('/media/koba/MULTIBOOT/peer/HBN_BIDS/')\n",
    "\n",
    "eye_mask_right_name=os.path.join(bids_dir,'source/nau_mask_right.nii.gz')\n",
    "eye_mask_right=nib.load(eye_mask_right_name)\n",
    "eye_mask_left_name=os.path.join(bids_dir,'source/nau_mask_left.nii.gz')\n",
    "eye_mask_left=nib.load(eye_mask_left_name)\n",
    "\n",
    "peer_run1_name=os.path.join(bids_dir,'derivatives/sub-NDARCT889DMB/ses-HBNsiteCBIC/func/sub-NDARCT889DMB_ses-HBNsiteCBIC_task-peer_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')\n",
    "peer_run1_confounds=pd.read_csv(os.path.join(bids_dir,'derivatives/sub-NDARCT889DMB/ses-HBNsiteCBIC/func/sub-NDARCT889DMB_ses-HBNsiteCBIC_task-peer_run-1_desc-confounds_timeseries.tsv'), delimiter='\\t')\n",
    "peer_run3_name=os.path.join(bids_dir,'derivatives/sub-NDARCT889DMB/ses-HBNsiteCBIC/func/sub-NDARCT889DMB_ses-HBNsiteCBIC_task-peer_run-2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')\n",
    "\n",
    "peer_run1=nib.load(peer_run1_name)\n",
    "\n",
    "json_functional='/media/koba/MULTIBOOT/peer/HBN_BIDS/sub-NDARCT889DMB/ses-HBNsiteCBIC/func/sub-NDARCT889DMB_ses-HBNsiteCBIC_task-peer_run-1_bold.json'\n",
    "\n",
    "# Load and display JSON\n",
    "with open(json_functional, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "#print(json.dumps(data, indent=4))\n",
    "\n",
    "print(\"Shape:\", peer_run1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa61e75-5c75-4a28-8ee2-a046b2af582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load eye positions via task file \n",
    "stimuli_values = pd.read_csv(os.path.join(bids_dir, 'source/stim_vals.csv'))\n",
    "\n",
    "# Repeat each point to match the fMRI's resolution\n",
    "stimuli_repeated = stimuli_values.loc[stimuli_values.index.repeat(5)].reset_index(drop=True)\n",
    "\n",
    "# Set up a custom gridspec layout: 2 rows, 2 columns, with the right column merged\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "gs = gridspec.GridSpec(2, 2, width_ratios=[1, 1])\n",
    "\n",
    "# Subplot for pos_x time series (top left)\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "stimuli_repeated.pos_x.plot.line(ax=ax0, label='pos_x', color='blue')\n",
    "ax0.set_ylabel('Position X')\n",
    "ax0.set_ylim(-1.2, 1.2)\n",
    "ax0.set_title(\"pos_x over time\")\n",
    "\n",
    "# Subplot for pos_y time series (bottom left)\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "stimuli_repeated.pos_y.plot.line(ax=ax1, label='pos_y', color='blue')\n",
    "ax1.set_xlabel('Time point')\n",
    "ax1.set_ylabel('Position Y')\n",
    "ax1.set_ylim(-1.2, 1.2)\n",
    "ax1.set_title(\"pos_y over time\")\n",
    "\n",
    "# Subplot for pos_x vs pos_y scatter plot (right, spanning both rows)\n",
    "ax2 = fig.add_subplot(gs[:, 1])\n",
    "ax2.scatter(stimuli_repeated.pos_x, stimuli_repeated.pos_y, color='blue', s=5, alpha=0.7)\n",
    "ax2.set_xlabel('Position X')\n",
    "ax2.set_ylabel('Position Y')\n",
    "ax2.set_xlim(-1.2, 1.2)\n",
    "ax2.set_ylim(-1.2, 1.2)\n",
    "ax2.set_title(\"pos_x vs pos_y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb036e-cbf8-4cd0-a117-501be17a920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the masks to the resolution of the functional image\n",
    "eye_mask_right_resampled = resample_to_img(\n",
    "    source_img=eye_mask_right,       # 3D mask to resample\n",
    "    target_img=peer_run1,            # 4D target image (spatial dims used)\n",
    "    interpolation='nearest'          # Use nearest neighbor to preserve binary values\n",
    ")\n",
    "\n",
    "eye_mask_left_resampled = resample_to_img(\n",
    "    source_img=eye_mask_left,       # 3D mask to resample\n",
    "    target_img=peer_run1,            # 4D target image (spatial dims used)\n",
    "    interpolation='nearest'          # Use nearest neighbor to preserve binary values\n",
    ")\n",
    "print(\"Mask shape before resampling:\", eye_mask_left.shape)\n",
    "print(\"Mask shape after resampling:\", eye_mask_left_resampled.shape)\n",
    "print(\"Shape of the functional scan:\", peer_run1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65ab81-de26-4ff3-a05a-1cb0364a3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_fmri_viewer(peer_run1, mask=eye_mask_right_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f9ff2-01a1-4fb0-a3ee-f5794100626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the image\n",
    "peer_run1_smoothed = smooth_img(peer_run1, fwhm=4)\n",
    "interactive_fmri_viewer(peer_run1_smoothed, mask=eye_mask_left_resampled,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c8710-92d5-4ccf-8318-2d4a079d4637",
   "metadata": {},
   "source": [
    " Functional data was corrected with field-map sequence <br>\n",
    " No slice-time correction was applied <br>\n",
    " Motion correction should be the first (and probably the only one that everyone would agree on) preprocessing step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4be54d-b0b1-4c51-b0cd-ecd8526667ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5919d0-6b6b-43f0-b353-17f9de310387",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_y_right=correlation_with_gaze_task(peer_run1_smoothed, mask=eye_mask_right_resampled, axis=\"pos_y\")\n",
    "correlation_y_left=correlation_with_gaze_task(peer_run1_smoothed, mask=eye_mask_left_resampled, axis=\"pos_y\")\n",
    "correlation_y = nib.Nifti1Image((correlation_y_right.get_fdata()+correlation_y_left.get_fdata()),\n",
    "                                affine=correlation_y_right.affine, header=correlation_y_right.header)\n",
    "\n",
    "correlation_x_right=correlation_with_gaze_task(peer_run1_smoothed, mask=eye_mask_right_resampled, axis=\"pos_x\")\n",
    "correlation_x_left=correlation_with_gaze_task(peer_run1_smoothed, mask=eye_mask_left_resampled, axis=\"pos_x\")\n",
    "correlation_x = nib.Nifti1Image((correlation_x_right.get_fdata()+correlation_x_left.get_fdata()),\n",
    "                                affine=correlation_x_right.affine, header=correlation_x_right.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c2da0-293f-4343-b560-765d534b8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "niplot.view_img(correlation_y, title='Y axis',draw_cross=False, bg_img='/home/koba/fsl/data/standard/MNI152_T1_1mm.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df139ca-0bdd-492c-9f91-621688437900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niplot.view_img(correlation_x, title='Y axis',draw_cross=True, bg_img='/home/koba/fsl/data/standard/MNI152_T1_1mm.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37989b08-e27f-4fe8-9c82-ec10b88071e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data array\n",
    "min_len=135\n",
    "peer_data=peer_run1_smoothed.get_fdata()\n",
    "data_x=correlation_x.get_fdata()\n",
    "max_idx = np.unravel_index(np.argmax(data_x), data_x.shape)\n",
    "max_val = data_x[max_idx]\n",
    "print(f\"Max correlation value with x: {max_val:.4f} at voxel location (x, y, z): {max_idx}\")\n",
    "\n",
    "voxel_ts=peer_data[max_idx[0],max_idx[1],max_idx[2],:]\n",
    "voxel_ts_norm = (voxel_ts - voxel_ts.min()) / (voxel_ts.max() - voxel_ts.min())  # [0,1]\n",
    "voxel_ts_rescaled_x = voxel_ts_norm * 2 - 1  # scale to [-1,1]\n",
    "\n",
    "data_y=correlation_y.get_fdata()\n",
    "max_idx = np.unravel_index(np.argmax(data_y), data_y.shape)\n",
    "max_val = data_y[max_idx]\n",
    "voxel_ts=peer_data[max_idx[0],max_idx[1],max_idx[2],:]\n",
    "voxel_ts_norm = (voxel_ts - voxel_ts.min()) / (voxel_ts.max() - voxel_ts.min())  # [0,1]\n",
    "voxel_ts_rescaled_y = voxel_ts_norm * 2 - 1  # scale to [-1,1]\n",
    "\n",
    "print(f\"Max correlation value with y: {max_val:.4f} at voxel location (x, y, z): {max_idx}\")\n",
    "\n",
    "# Rescale stimulus pos_x\n",
    "stim_x = stimuli_repeated.pos_x.iloc[:min_len].values\n",
    "stim_x_norm = (stim_x - stim_x.min()) / (stim_x.max() - stim_x.min())\n",
    "stim_x_rescaled = stim_x_norm * 2 - 1\n",
    "\n",
    "# Rescale stimulus pos_y\n",
    "stim_y = stimuli_repeated.pos_y.iloc[:min_len].values\n",
    "stim_y_norm = (stim_y - stim_y.min()) / (stim_y.max() - stim_y.min())\n",
    "stim_y_rescaled = stim_y_norm * 2 - 1\n",
    "\n",
    "# Set up the grid\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "# Top-left: stimulus X vs eye center X\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "ax0.plot(stim_x_rescaled, label='stim_x', color='blue')\n",
    "ax0.plot(voxel_ts_rescaled_x , label='eye_x', color='orange', alpha=0.7)\n",
    "ax0.set_title('X Coordinate Comparison')\n",
    "ax0.legend(loc='lower right')\n",
    "\n",
    "# Bottom-left: stimulus Y vs eye center Y\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax1.plot(stim_y_rescaled, label='stim_y', color='blue')\n",
    "ax1.plot(voxel_ts_rescaled_y , label='eye_y', color='green', alpha=0.7)\n",
    "ax1.set_title('Y Coordinate Comparison')\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# Right: scatter plot (stimulus vs eye)\n",
    "ax2 = fig.add_subplot(gs[:, 1])\n",
    "ax2.scatter(stim_x_rescaled, stim_y_rescaled, label='stimulus', color='blue', s=10, alpha=0.5)\n",
    "ax2.scatter(voxel_ts_rescaled_x, voxel_ts_rescaled_y , label='eye', color='orange', s=10, alpha=0.5)\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_xlim(-1.2, 1.2)\n",
    "ax2.set_ylim(-1.2, 1.2)\n",
    "ax2.set_title(\"Stimulus vs Eye Trajectory\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ac171-effd-4892-9081-135006098dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load data from image (shape: X, Y, Z, T)\n",
    "data_4d = peer_run1.get_fdata()\n",
    "original_shape = data_4d.shape  # (x, y, z, t)\n",
    "n_voxels = np.prod(original_shape[:-1])\n",
    "n_timepoints = original_shape[-1]\n",
    "\n",
    "# 2. Reshape to 2D: (voxels, time)\n",
    "data_2d = data_4d.reshape(-1, n_timepoints).T  # Shape: (T, voxels)\n",
    "\n",
    "# 3. Prepare confounds (remove NaNs/infs)\n",
    "confounds_clean = peer_run1_confounds[[\"white_matter\", \"csf\", \"framewise_displacement\", \"global_signal\",\"trans_x\",\"trans_y\",\"trans_z\",\"rot_x\",\"rot_y\",\"rot_z\"]].copy()\n",
    "confounds_clean = confounds_clean.replace([np.inf, -np.inf], np.nan)\n",
    "confounds_clean = confounds_clean.fillna(confounds_clean.mean())\n",
    "confounds_array = confounds_clean.values\n",
    "\n",
    "# 4. Apply clean: regress confounds, detrend, standardize, and bandpass\n",
    "TR = 0.8  # Replace with actual TR in seconds if different\n",
    "cleaned_2d = clean(\n",
    "    data_2d,\n",
    "    confounds=None,\n",
    "    detrend=False,\n",
    "    standardize=\"zscore_sample\",\n",
    "    low_pass=0.04,\n",
    "    high_pass=0.01,\n",
    "    t_r=TR\n",
    ")\n",
    "\n",
    "# 5. Reshape back to 4D\n",
    "cleaned_4d = cleaned_2d.T.reshape(original_shape)\n",
    "\n",
    "# 6. Create cleaned Nifti image\n",
    "peer1_clean_img = nib.Nifti1Image(cleaned_4d, affine=peer_run1_smoothed.affine, header=peer_run1_smoothed.header)\n",
    "\n",
    "\n",
    "#interactive_fmri_viewer(peer1_clean_img)\n",
    "peer1_clean_img = smooth_img(peer1_clean_img, fwhm=4)\n",
    "interactive_fmri_viewer(peer1_clean_img, mask=eye_mask_left_resampled,)\n",
    "\n",
    "correlation_y_right=correlation_with_gaze_task(peer1_clean_img, mask=eye_mask_right_resampled, axis=\"pos_y\")\n",
    "correlation_y_left=correlation_with_gaze_task(peer1_clean_img, mask=eye_mask_left_resampled, axis=\"pos_y\")\n",
    "correlation_y = nib.Nifti1Image((correlation_y_right.get_fdata()+correlation_y_left.get_fdata()),\n",
    "                                affine=correlation_y_right.affine, header=correlation_y_right.header)\n",
    "\n",
    "correlation_x_right=correlation_with_gaze_task(peer1_clean_img, mask=eye_mask_right_resampled, axis=\"pos_x\")\n",
    "correlation_x_left=correlation_with_gaze_task(peer1_clean_img, mask=eye_mask_left_resampled, axis=\"pos_x\")\n",
    "correlation_x = nib.Nifti1Image((correlation_x_right.get_fdata()+correlation_x_left.get_fdata()),\n",
    "                                affine=correlation_x_right.affine, header=correlation_x_right.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab8652-98c5-4b92-ab51-2fdabb5fe1af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niplot.view_img(correlation_y, title='Y axis',draw_cross=False, bg_img='/home/koba/fsl/data/standard/MNI152_T1_1mm.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3aebe5-bfda-4f38-a288-a8734ebd0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "niplot.view_img(correlation_x, title='Y axis',draw_cross=False, bg_img='/home/koba/fsl/data/standard/MNI152_T1_1mm.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572dd94-ccff-4c27-9df1-f29a0d82c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def top_10_percent_mask(masked_data):\n",
    "    \"\"\"\n",
    "    For each time point, create a mask selecting voxels in the top 10% brightness.\n",
    "    \n",
    "    Parameters:\n",
    "    masked_data : np.ndarray\n",
    "        Array of shape (timepoints, voxels)\n",
    "        \n",
    "    Returns:\n",
    "    mask : np.ndarray (bool)\n",
    "        Boolean array of shape (timepoints, voxels) where True indicates top 10% voxels.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(masked_data, dtype=bool)\n",
    "    \n",
    "    for t in range(masked_data.shape[0]):\n",
    "        data_t = masked_data[t]\n",
    "        threshold = np.percentile(data_t, 10)  # top 10% threshold\n",
    "        mask[t] = data_t >= threshold\n",
    "    \n",
    "    return mask\n",
    "\n",
    "masked_data=apply_mask(peer_run1_smoothed,eye_mask_right_resampled)\n",
    "#masked_img=nib.Nifti1Image(masked_data, affine=peer_run1_smoothed.affine, header=peer_run1_smoothed.header)\n",
    "\n",
    "# Usage\n",
    "top10_mask = top_10_percent_mask(masked_data)  # shape: (135, 4177)\n",
    "\n",
    "\n",
    "# top10_mask shape: (135, 4177) - timepoints × voxels\n",
    "# unmask expects shape (n_samples, n_features), so transpose to (4177, 135)\n",
    "top10_mask_T = top10_mask.astype(float)  # convert bool to float (1.0/0.0)\n",
    "\n",
    "# Unmask returns a 4D image (x, y, z, time)\n",
    "top10_mask_img = unmask(top10_mask_T, eye_mask_right_resampled)\n",
    "\n",
    "# Save if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc7854-f718-4a53-a050-333ca698f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the cluster mask from eye mask to leave optic nerve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d1e43-9da4-4427-b74d-30b182fca957",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_fmri_viewer(peer_run1_smoothed,mask=top10_mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2666315-c276-4359-8d00-035c8df942d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = compute_weighted_centers(peer_run1_smoothed, top10_mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0efd03-eac7-4695-a938-b1bdf6d5854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean input\n",
    "centers_valid = centers[~np.isnan(centers).any(axis=1)]\n",
    "pos_x_valid = stimuli_repeated.pos_x.iloc[:len(centers_valid)]\n",
    "pos_y_valid = stimuli_repeated.pos_y.iloc[:len(centers_valid)]\n",
    "\n",
    "# Store both r and p\n",
    "correlations = {\n",
    "    'x_vs_pos_x': pearsonr(centers_valid[:, 0], pos_x_valid),\n",
    "    'y_vs_pos_x': pearsonr(centers_valid[:, 1], pos_x_valid),\n",
    "    'z_vs_pos_x': pearsonr(centers_valid[:, 2], pos_x_valid),\n",
    "    'x_vs_pos_y': pearsonr(centers_valid[:, 0], pos_y_valid),\n",
    "    'y_vs_pos_y': pearsonr(centers_valid[:, 1], pos_y_valid),\n",
    "    'z_vs_pos_y': pearsonr(centers_valid[:, 2], pos_y_valid),\n",
    "}\n",
    "\n",
    "# Print results\n",
    "for k, (r, p) in correlations.items():\n",
    "    print(f\"{k}: r = {r:.4f}, p = {p:.4g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14823d-3435-4f04-a64a-ce8609d2603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure same length\n",
    "min_len = min(len(centers_valid), len(stimuli_repeated))\n",
    "\n",
    "# Rescale eye center X (from centers_valid[:, 0])\n",
    "voxel_ts_x = voxel_ts_rescaled_x_left#centers_valid[:min_len, 0]\n",
    "voxel_ts_x_norm = (voxel_ts_x - voxel_ts_x.min()) / (voxel_ts_x.max() - voxel_ts_x.min())\n",
    "voxel_ts_rescaled_x = voxel_ts_x_norm * 2 - 1\n",
    "\n",
    "# Rescale eye center Z (from centers_valid[:, 2], used as vertical/Y)\n",
    "voxel_ts_z = voxel_ts_rescaled_y_left#centers_valid[:min_len, 2]\n",
    "voxel_ts_z_norm = (voxel_ts_z - voxel_ts_z.min()) / (voxel_ts_z.max() - voxel_ts_z.min())\n",
    "voxel_ts_rescaled_y = voxel_ts_z_norm * 2 - 1\n",
    "\n",
    "# Rescale stimulus pos_x\n",
    "stim_x = voxel_ts_rescaled_x_right#stimuli_repeated.pos_x.iloc[:min_len].values\n",
    "stim_x_norm = (stim_x - stim_x.min()) / (stim_x.max() - stim_x.min())\n",
    "stim_x_rescaled = stim_x_norm * 2 - 1\n",
    "\n",
    "# Rescale stimulus pos_y\n",
    "stim_y = voxel_ts_rescaled_y_right *-1#stimuli_repeated.pos_y.iloc[:min_len].values\n",
    "stim_y_norm = (stim_y - stim_y.min()) / (stim_y.max() - stim_y.min())\n",
    "stim_y_rescaled = stim_y_norm * 2 - 1\n",
    "\n",
    "# Set up the grid\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "# Top-left: stimulus X vs eye center X\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "ax0.plot(stim_x_rescaled, label='stim_x', color='blue')\n",
    "ax0.plot(voxel_ts_rescaled_x * -1, label='eye_x', color='orange', alpha=0.7)\n",
    "ax0.set_title('X Coordinate Comparison')\n",
    "ax0.legend(loc='lower right')\n",
    "\n",
    "# Bottom-left: stimulus Y vs eye center Y\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax1.plot(stim_y_rescaled, label='stim_y', color='blue')\n",
    "ax1.plot(voxel_ts_rescaled_y * -1, label='eye_y', color='green', alpha=0.7)\n",
    "ax1.set_title('Y Coordinate Comparison')\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# Right: scatter plot (stimulus vs eye)\n",
    "ax2 = fig.add_subplot(gs[:, 1])\n",
    "ax2.scatter(stim_x_rescaled, stim_y_rescaled, label='stimulus', color='blue', s=10, alpha=0.5)\n",
    "ax2.scatter(voxel_ts_rescaled_x * -1, voxel_ts_rescaled_y * -1, label='eye', color='orange', s=10, alpha=0.5)\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_xlim(-1.2, 1.2)\n",
    "ax2.set_ylim(-1.2, 1.2)\n",
    "ax2.set_title(\"Stimulus vs Eye Trajectory\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d8d7a-8f8b-47a2-83ca-c1bf6dba7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_ts_rescaled_x_right=voxel_ts_rescaled_x\n",
    "voxel_ts_rescaled_y_right=voxel_ts_rescaled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd944c7e-7226-4ca2-b982-6bef7eb8ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_ts_rescaled_x_left=voxel_ts_rescaled_x\n",
    "voxel_ts_rescaled_y_left=voxel_ts_rescaled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fb070-d4bb-4f0d-b0be-e188cb6fc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(voxel_ts_rescaled_x_right, voxel_ts_rescaled_x_left)\n",
    "\n",
    "# Print correlation coefficient and p-value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fe7c8-3e96-4a57-8978-0a2503d4e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Compute correlation\n",
    "r, p = pearsonr(voxel_ts_rescaled_y_right, voxel_ts_rescaled_y_left)\n",
    "\n",
    "# Create scatter plot with regression line and confidence interval\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.regplot(\n",
    "    x=voxel_ts_rescaled_y_right,\n",
    "    y=voxel_ts_rescaled_y_left,\n",
    "    ci=95,\n",
    "    scatter_kws={'alpha': 0.6, 's': 40},\n",
    "    line_kws={'color': 'red'}\n",
    ")\n",
    "plt.title(f\"Right vs. Left Eye X (rescaled)\\nr = {r:.4f}, p = {p:.2e}\")\n",
    "plt.xlabel(\"Right Eye X (rescaled)\")\n",
    "plt.ylabel(\"Left Eye X (rescaled)\")\n",
    "plt.grid(True)\n",
    "plt.axis(\"equal\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439eea6-76d9-406b-b1c4-63a385b0b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure confounds_clean is a DataFrame with column names\n",
    "if isinstance(confounds_clean, np.ndarray):\n",
    "    confounds_clean = pd.DataFrame(confounds_clean, columns=[f\"confound_{i}\" for i in range(confounds_clean.shape[1])])\n",
    "\n",
    "# Combine centers and confounds into one DataFrame\n",
    "combined = pd.concat([\n",
    "    pd.DataFrame(centers_valid, columns=[\"x\", \"y\", \"z\"]),\n",
    "    confounds_clean.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Drop rows with NaNs or Infs\n",
    "combined = combined.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Now split back\n",
    "centers_clean = combined[[\"x\", \"y\", \"z\"]].values\n",
    "confounds_cleaned = combined.drop(columns=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "# Compute correlations\n",
    "results = []\n",
    "for i, coord_label in enumerate([\"x\", \"y\", \"z\"]):\n",
    "    for conf_name in confounds_cleaned.columns:\n",
    "        r, p = pearsonr(centers_clean[:, i], confounds_cleaned[conf_name].values)\n",
    "        results.append({\n",
    "            \"center_axis\": coord_label,\n",
    "            \"confound\": conf_name,\n",
    "            \"r\": r,\n",
    "            \"p\": p\n",
    "        })\n",
    "\n",
    "# Format and show results\n",
    "correlation_df = pd.DataFrame(results)\n",
    "correlation_df_sorted = correlation_df.reindex(correlation_df.r.abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(correlation_df_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c097cc-353a-4f35-a8c4-226291defa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correlation_df_stim_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94a71b-fd0f-44d4-861b-038cf1b92b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14bf683-fcbf-45bc-b846-6281a63f4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure confounds_clean is a DataFrame with column names\n",
    "if isinstance(confounds_clean, np.ndarray):\n",
    "    confounds_clean = pd.DataFrame(confounds_clean, columns=[f\"confound_{i}\" for i in range(confounds_clean.shape[1])])\n",
    "\n",
    "# Ensure stimuli_repeated has exactly 2 columns: pos_x and pos_y\n",
    "stimuli_df = stimuli_repeated[[\"pos_x\", \"pos_y\"]].copy()\n",
    "stimuli_df.columns = [\"x\", \"y\"]  # Rename to align with rest of code\n",
    "\n",
    "# Add dummy z = 0 (since your original loop expects x, y, z)\n",
    "stimuli_df[\"z\"] = 0\n",
    "\n",
    "# Combine with confounds\n",
    "combined = pd.concat([\n",
    "    stimuli_df.reset_index(drop=True),\n",
    "    confounds_clean.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Drop rows with NaNs or Infs\n",
    "combined = combined.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Split\n",
    "stimuli_clean = combined[[\"x\", \"y\", \"z\"]].values\n",
    "confounds_cleaned = combined.drop(columns=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "# Compute correlations\n",
    "results = []\n",
    "for i, coord_label in enumerate([\"x\", \"y\", \"z\"]):\n",
    "    for conf_name in confounds_cleaned.columns:\n",
    "        r, p = pearsonr(stimuli_clean[:, i], confounds_cleaned[conf_name].values)\n",
    "        results.append({\n",
    "            \"stim_axis\": coord_label,\n",
    "            \"confound\": conf_name,\n",
    "            \"r\": r,\n",
    "            \"p\": p\n",
    "        })\n",
    "\n",
    "# Format and show\n",
    "correlation_df_stim = pd.DataFrame(results)\n",
    "correlation_df_stim_sorted = correlation_df_stim.reindex(correlation_df.r.abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(correlation_df_stim_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c1212-d8dd-4788-ad0a-eb5c4777d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(correlation_df_stim.iloc[:19].r,correlation_df.iloc[:19].r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388d0c8-3daa-4043-a619-a72feec0f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import decimate, welch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def estimate_nyquist_rate(signal, fs):\n",
    "    # Welch's method to estimate power spectrum\n",
    "    freqs, power = welch(signal, fs=fs)\n",
    "    # Estimate cutoff frequency where 95% of power is contained\n",
    "    cumulative_power = np.cumsum(power) / np.sum(power)\n",
    "    cutoff_idx = np.searchsorted(cumulative_power, 0.95)\n",
    "    f_max = freqs[cutoff_idx]\n",
    "    nyquist_rate = 2 * f_max\n",
    "    return nyquist_rate, f_max, freqs, power\n",
    "\n",
    "# Example: suppose your original stimulus sampling rate is 60 Hz\n",
    "fs_original = 0.8  # Hz\n",
    "nyquist_rate, f_max, freqs, power = estimate_nyquist_rate(stim_x, fs=fs_original)\n",
    "\n",
    "# Plot power spectrum\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.semilogy(freqs, power)\n",
    "plt.axvline(f_max, color='r', linestyle='--', label=f\"95% Power Cutoff = {f_max:.2f} Hz\")\n",
    "plt.title(\"Stim_x Power Spectrum (Welch)\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Downsample if needed\n",
    "factor = int(np.floor(fs_original / nyquist_rate)) if nyquist_rate > 0 else 1\n",
    "stim_x_resampled = decimate(stim_x, factor, ftype='fir') if factor > 1 else stim_x\n",
    "stim_y_resampled = decimate(stim_y, factor, ftype='fir') if factor > 1 else stim_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6c6dc2-aeb8-4ea3-9210-16607d237ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import decimate\n",
    "\n",
    "# Downsample centers[:, 0] with same factor\n",
    "if nyquist_rate > 0:\n",
    "    downsample_factor = int(np.floor(fs_original / nyquist_rate))\n",
    "else:\n",
    "    downsample_factor = 1  # fallback\n",
    "\n",
    "# Ensure factor is at least 1\n",
    "downsample_factor = max(downsample_factor, 1)\n",
    "\n",
    "# Apply FIR decimation to centers[:, 0]\n",
    "centers_x_downsampled = decimate(centers[:, 0], downsample_factor, ftype='fir') if downsample_factor > 1 else centers[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351b96e-908a-4276-b071-b31e129403c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(centers_x_downsampled)\n",
    "plt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0558ec-3739-44b3-942d-12ae2a907565",
   "metadata": {},
   "source": [
    "# MVPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7119a-0d8e-460d-b1cc-e6d14614b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "peer_run1_smoothed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d36e13-76db-4696-a0bd-bf556df7b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.masking import apply_mask\n",
    "from nilearn.plotting import plot_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Apply the mask to extract voxel time series\n",
    "# Returns shape: (n_timepoints, n_voxels)\n",
    "masked_data = apply_mask(peer_run1_smoothed, eye_mask_left_resampled)\n",
    "\n",
    "# Transpose to shape: (n_voxels, n_timepoints)\n",
    "masked_data = masked_data\n",
    "\n",
    "# Optionally z-score across time to normalize\n",
    "from scipy.stats import zscore\n",
    "masked_data = zscore(masked_data, axis=1)\n",
    "\n",
    "# Compute correlation matrix across voxels\n",
    "correlation_matrix = np.corrcoef(masked_data)\n",
    "\n",
    "# Plot correlation matrix\n",
    "plot_matrix(correlation_matrix, figure=(8, 6),\n",
    "            labels=None, auto_fit=True,\n",
    "            title='Voxel-wise Correlation (Left Eye Region)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3269d0e-0b12-43bc-b19f-0007407d5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d9c6c-de19-4279-94de-475551beaf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voxel_ts=smoothed_signal\n",
    "voxel_ts_norm = (voxel_ts - voxel_ts.min()) / (voxel_ts.max() - voxel_ts.min())  # [0,1]\n",
    "voxel_ts_rescaled_x = voxel_ts_norm * 2 - 1  # scale to [-1,1]\n",
    "\n",
    "data_y=correlation_y.get_fdata()\n",
    "max_idx = np.unravel_index(np.argmax(data_y), data_y.shape)\n",
    "max_val = data_y[max_idx]\n",
    "voxel_ts=smoothed_signal\n",
    "voxel_ts_norm = (voxel_ts - voxel_ts.min()) / (voxel_ts.max() - voxel_ts.min())  # [0,1]\n",
    "voxel_ts_rescaled_y = voxel_ts_norm * 2 - 1  # scale to [-1,1]\n",
    "\n",
    "print(f\"Max correlation value with y: {max_val:.4f} at voxel location (x, y, z): {max_idx}\")\n",
    "\n",
    "# Rescale stimulus pos_x\n",
    "stim_x = stimuli_repeated.pos_x.iloc[:min_len].values\n",
    "stim_x_norm = (stim_x - stim_x.min()) / (stim_x.max() - stim_x.min())\n",
    "stim_x_rescaled = stim_x_norm * 2 - 1\n",
    "\n",
    "# Rescale stimulus pos_y\n",
    "stim_y = stimuli_repeated.pos_y.iloc[:min_len].values\n",
    "stim_y_norm = (stim_y - stim_y.min()) / (stim_y.max() - stim_y.min())\n",
    "stim_y_rescaled = stim_y_norm * 2 - 1\n",
    "\n",
    "# Set up the grid\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "# Top-left: stimulus X vs eye center X\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "ax0.plot(stim_x_rescaled, label='stim_x', color='blue')\n",
    "ax0.plot(voxel_ts_rescaled_x , label='eye_x', color='orange', alpha=0.7)\n",
    "ax0.set_title('X Coordinate Comparison')\n",
    "ax0.legend(loc='lower right')\n",
    "\n",
    "# Bottom-left: stimulus Y vs eye center Y\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax1.plot(stim_y_rescaled, label='stim_y', color='blue')\n",
    "ax1.plot(voxel_ts_rescaled_y , label='eye_y', color='green', alpha=0.7)\n",
    "ax1.set_title('Y Coordinate Comparison')\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# Right: scatter plot (stimulus vs eye)\n",
    "ax2 = fig.add_subplot(gs[:, 1])\n",
    "ax2.scatter(stim_x_rescaled, stim_y_rescaled, label='stimulus', color='blue', s=10, alpha=0.5)\n",
    "ax2.scatter(voxel_ts_rescaled_x, voxel_ts_rescaled_y , label='eye', color='orange', s=10, alpha=0.5)\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_xlim(-1.2, 1.2)\n",
    "ax2.set_ylim(-1.2, 1.2)\n",
    "ax2.set_title(\"Stimulus vs Eye Trajectory\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcb3e6-a8f3-4ce0-a392-413505649a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Original signal\n",
    "signal = correlation_matrix[:, 0]\n",
    "\n",
    "# Apply Savitzky-Golay filter (window size must be odd and < len(signal))\n",
    "smoothed_signal = savgol_filter(signal, window_length=11, polyorder=3)\n",
    "\n",
    "# Plot original and smoothed\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(signal, label=\"Original\", alpha=0.5)\n",
    "plt.plot(smoothed_signal, label=\"Smoothed (Savitzky-Golay)\", linewidth=2)\n",
    "plt.title(\"Denoising with Savitzky-Golay Filter\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3adca-1a8a-4b73-b7a8-5c99feb4afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_mask_data = eye_mask_left_resampled.get_fdata().astype(bool)\n",
    "\n",
    "# Get shape\n",
    "x, y, z = left_mask_data.shape\n",
    "\n",
    "# Define y-splits (3 equal parts)\n",
    "y1 = y // 3\n",
    "y2 = 2 * y // 3\n",
    "\n",
    "# Create three sub-masks\n",
    "mask_left_part1 = np.zeros_like(left_mask_data)\n",
    "mask_left_part2 = np.zeros_like(left_mask_data)\n",
    "mask_left_part3 = np.zeros_like(left_mask_data)\n",
    "\n",
    "# Apply original mask within y segments\n",
    "mask_left_part1[:, :y1, :] = left_mask_data[:, :y1, :]\n",
    "mask_left_part2[:, y1:y2, :] = left_mask_data[:, y1:y2, :]\n",
    "mask_left_part3[:, 10:, :] = left_mask_data[:, 10:, :]\n",
    "\n",
    "# Convert back to NIfTI images using the same affine\n",
    "mask_img1 = nib.Nifti1Image(mask_left_part1.astype(np.uint8), affine=eye_mask_left_resampled.affine)\n",
    "mask_img2 = nib.Nifti1Image(mask_left_part2.astype(np.uint8), affine=eye_mask_left_resampled.affine)\n",
    "mask_img3 = nib.Nifti1Image(mask_left_part3.astype(np.uint8), affine=eye_mask_left_resampled.affine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f7299-cb9a-4379-be79-540ff0e700b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "niplot.view_img(mask_img3,bg_img='/home/koba/fsl/data/standard/MNI152_T1_1mm.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe42ee-12ab-43f0-9578-e29406d36877",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_fmri_viewer(smooth_img, mask=mask_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d05ba-f7cd-4826-8623-2d2dcec2892c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
